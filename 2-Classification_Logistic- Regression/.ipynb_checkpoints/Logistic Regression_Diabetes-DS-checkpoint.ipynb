{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CrhdKIt9qCZ5"
   },
   "source": [
    "## Introduction\n",
    "In linear regression, the type of data we deal with is quantitative, whereas we use classification models to deal with qualitative data or categorical data. The algorithms used for solving a classification problem first predict the probability of each of the categories of the qualitative variables, as the basis for making the classification. And, as the probabilities are continuous numbers, classification using probabilities also behave like regression methods. \n",
    "Logistic regression is one such type of classification model which is used to classify the dependent variable into two or more classes or categories. \n",
    "\n",
    "##### why are we calling a classification model the Logistic ‘Regression’?\n",
    "The reason behind this is that just like Linear Regression, logistic regression starts from a linear equation. However, this equation consists of log-odds which is further passed through a sigmoid function which squeezes the output of the linear equation to a probability between 0 and 1. And, we can decide a decision boundary and use this probability to conduct classification task. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T_NCj8WLqCZ9"
   },
   "source": [
    "## Logistic Regression\n",
    "\n",
    "Logistic regression is one such regression algorithm which can be used for performing classification problems. It calculates the probability that a given value belongs to a specific class. If the probability is more than 50%, it assigns the value in that particular class else if the probability is less than 50%, the value is assigned to the other class. Therefore, we can say that logistic regression acts as a binary classifier.\n",
    "\n",
    "###### Working of a Logistic Model\n",
    "For linear regression, the model is defined by:\n",
    "$y = \\beta_0 + \\beta_1x  $       - (i)\n",
    "\n",
    "and for logistic regression, we calculate probability, i.e. y is the probability of a given variable x belonging to a certain class. Thus, it is obvious that the value of y should lie between 0 and 1.\n",
    "\n",
    "But, when we use equation(i) to calculate probability, we would get values less than 0 as well as greater than 1. That doesn’t make any sense\n",
    ".\n",
    "So, we need to use such an equation which always gives values between 0 and 1, as we desire while calculating the probability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eAYZkYhHqCZ-"
   },
   "source": [
    "**Prediction**\n",
    "\n",
    "<img src=\"prediction.PNG\" width=\"300\">\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wLbJZmjLqCZ_"
   },
   "source": [
    "## Evaluation of a Classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lL_KCM7LqCZ_"
   },
   "source": [
    "In machine learning, once we have a result of the classification problem, how do we measure how accurate our classification is?\n",
    "For a  regression problem, we have different metrics like R Squared score, Mean Squared Error etc. what are the metrics to measure the credibility of a classification model?\n",
    "\n",
    "Metrics\n",
    "In a regression problem, the accuracy is generally measured in terms of the difference in the actual values and the predicted values.\n",
    "In a classification problem, the credibility of the model is measured using the confusion matrix generated, i.e., how accurately the true positives and true negatives were predicted.\n",
    "The different metrics used for this purpose are:\n",
    "- Accuracy\n",
    "- Recall\n",
    "- Precision\n",
    "- F1 Score\n",
    "- Specificity\n",
    "- AUC( Area Under the Curve)\n",
    "- ROC(Receiver Operator Characteristic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uHcIVIjbqCaA"
   },
   "source": [
    "### Confusion Matrix\n",
    "\n",
    "A typical confusion matrix looks like the figure shown.\n",
    "\n",
    "<img src=\"confusionMatrix.PNG\" width=\"300\">\n",
    "\n",
    "Where the terms have the meaning:\n",
    "\n",
    "\t__True Positive(TP):__ A result that was predicted as positive by the classification model and also is positive\n",
    "\n",
    "\t__True Negative(TN):__ A result that was predicted as negative by the classification model and also is negative\n",
    "\n",
    "\t__False Positive(FP):__ A result that was predicted as positive by the classification model but actually is negative\n",
    "\n",
    "\t__False Negative(FN):__ A result that was predicted as negative by the classification model but actually is positive.\n",
    "\n",
    "The Credibility of the model is based on how many correct predictions did the model do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q9tyVh7fqCaB"
   },
   "source": [
    "### Accuracy\n",
    "The mathematical formula is :\n",
    "\n",
    "   __Accuracy__= $ \\frac{ (TP+TN)}{(TP+TN+FP+FN)} $\n",
    "    \n",
    "Or, it can be said that it’s defined as the total number of correct classifications divided by the total number of classifications.\n",
    "Its is not the correct for inbalanc data beacause its always show you high accurancy becoz its bais to the high count data in binary classification\n",
    "becoz its not calculate the error / its won't count the error "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R6cLmt4cqCaB"
   },
   "source": [
    "#### Recall or Sensitivity\n",
    "The mathematical formula is:\n",
    "\n",
    "   __Recall__= $ \\frac{ TP}{(TP+FN)} $\n",
    "\n",
    "Or, as the name suggests, it is a measure of: from the total number of positive results how many positives were correctly predicted by the model.\n",
    "\n",
    "It shows how relevant the model is, in terms of positive results only.\n",
    "\n",
    "Consider a classification model , the model gave 50 correct predictions(TP) but failed to identify 200 cancer patients(FN). Recall in that case will be:\n",
    "\n",
    "Recall=$ \\frac {50}{(50+200)} $= 0.2 (The model was able to recall only 20% of the cancer patients)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mO5ITCBlqCaC"
   },
   "source": [
    "### Precision\n",
    "\n",
    "Precision is a measure of amongst all the positive predictions, how many of them were actually positive. Mathematically,\n",
    "\n",
    "Precision=$ \\frac {TP}{(TP+FP)} $\n",
    "\n",
    "Let’s suppose in the previous example, the model identified 50 people as cancer patients(TP) but also raised a  false alarm for 100 patients(FP). Hence,\n",
    "\n",
    "Precision=$ \\frac {50}{(50+100)} $=0.33 (The model only has a precision of 33%)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NvwwErkDqCaC"
   },
   "source": [
    "### But we have a problem!!\n",
    "\n",
    "As evident from the previous example, the model had a very high Accuracy but performed poorly in terms of Precision and Recall. So, necessarily _Accuracy_ is not the metric to use for evaluating the model in this case.\n",
    "\n",
    "Imagine a scenario, where the requirement was that the model recalled all the defaulters who did not pay back the loan. Suppose there were 10 such defaulters and to recall those 10 defaulters, and the model gave you 20 results out of which only the 10 are the actual defaulters. Now, the recall of the model is 100%, but the precision goes down to 50%.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x99V_GbAqCaD"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### A Trade-off?\n",
    "\n",
    "<img src=\"tradeoff.PNG\" width=\"300\">\n",
    "\n",
    "As observed from the graph, with an increase in the Recall, there is a drop in Precision of the model.\n",
    "\n",
    "So the question is - what to go for? Precision or Recall?\n",
    "\n",
    "Well, the answer is: it depends on the business requirement.\n",
    "\n",
    "For example, if you are predicting cancer, you need a 100 % recall. But suppose you are predicting whether a person is innocent or not, you need 100% precision.\n",
    "\n",
    "Can we maximise both at the same time? No\n",
    "\n",
    "So, there is a need for a better metric then?\n",
    "\n",
    "Yes. And it’s called an _F1 Score_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nXItOE5XqCaD"
   },
   "source": [
    "### F1 Score\n",
    "\n",
    "From the previous examples, it is clear that we need a metric that considers both Precision and Recall for evaluating a model. One such metric is the F1 score.\n",
    "\n",
    "F1 score is defined as the harmonic mean of Precision and Recall. \n",
    "\n",
    "The mathematical formula is:\n",
    "        F1 score= $ \\frac {2*((Precision*Recall)}{(Precision+Recall))} $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uj74wseaqCaE"
   },
   "source": [
    "### Specificity or True Negative Rate\n",
    "\n",
    "This represents how specific is the model while predicting the True Negatives.\n",
    "Mathematically,\n",
    "\n",
    "   Specificity=$ \\frac {TN}{(TN+FP)} $\n",
    "Or, it can be said that it quantifies the total number of negatives predicted by the model with respect to the total number of actual negative or non favorable outcomes.\n",
    "\n",
    "Similarly, False Positive rate can be defined as:  (1- specificity)\n",
    "Or,  $ \\frac {FP}{(TN+FP)} $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kMHp_s7rqCaE"
   },
   "source": [
    "### ROC(Receiver Operator Characteristic)\n",
    "\n",
    "We know that the classification algorithms work on the concept of probability of occurrence of the possible outcomes. A probability value lies between 0 and 1. Zero means that there is no probability of occurrence and one means that the occurrence is certain.\n",
    "\n",
    "But while working with real-time data, it has been observed that we seldom get a perfect 0 or 1 value. Instead of that, we get different decimal values lying between 0 and 1. Now the question is if we are not getting binary probability values how are we actually determining the class in our classification problem?\n",
    "\n",
    "There comes the concept of Threshold. A threshold is set, any probability value below the threshold is a negative outcome, and anything more than the threshold is a favourable or the positive outcome. For Example, if the threshold is 0.5, any probability value below 0.5 means a negative or an unfavourable outcome and any value above 0.5 indicates a positive or favourable outcome. \n",
    "\n",
    "Now, the question is, what should be an ideal threshold?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1egTEjrcqCaF"
   },
   "source": [
    "The following diagram shows a typical logistic regression curve.\n",
    "<img src=\"logisticRegression.PNG\" width=\"300\">\n",
    "\n",
    "* The horizontal lines represent the various values of thresholds ranging from 0 to 1.\n",
    "* Let’s suppose our classification problem was to identify the obese people from the given data.\n",
    "* The green markers represent obese people and the red markers represent the non-obese people.\n",
    "* Our confusion matrix will depend on the value of the threshold chosen by us.\n",
    "* For Example, if 0.25 is the threshold then\n",
    "        TP(actually obese)=3\n",
    "        TN(actually not obese)=2\n",
    "        FP(Not obese but predicted obese)=2(the two red squares above the 0.25 line)\n",
    "        FN(Obese but predicted as not obese )=1(Green circle below 0.25line  )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TSJMelvEqCaF"
   },
   "source": [
    "A typical ROC curve looks like the following figure.\n",
    "<img src=\"ROC.PNG\" width=\"300\">\n",
    "\n",
    "* Mathematically, it represents the various confusion matrices for various thresholds. Each black dot is one confusion matrix.\n",
    "* The green dotted line represents the scenario when the true positive rate equals the false positive rate.\n",
    "* As evident from the curve, as we move from the rightmost dot towards left, after a certain threshold, the false positive rate decreases.\n",
    "* After some time, the false positive rate becomes zero.\n",
    "* The point encircled in green is the best point as it predicts all the values correctly and keeps the False positive as a minimum.\n",
    "* But that is not a rule of thumb. Based on the requirement, we need to select the point of a threshold.\n",
    "* The ROC curve answers our question of which threshold to choose.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KeyH61AyqCaF"
   },
   "source": [
    "### But we have a confusion!!\n",
    "\n",
    "Let’s suppose that we used different classification algorithms, and different ROCs for the corresponding algorithms have been plotted.\n",
    "The question is: which algorithm to choose now?\n",
    "The answer is to calculate the area under each ROC curve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "89J1KbFJqCaF"
   },
   "source": [
    "#### AUC(Area Under Curve)\n",
    "\n",
    "<img src=\"AUC.PNG\" width=\"300\">\n",
    "\n",
    "* It helps us to choose the best model amongst the models for which we have plotted the ROC curves\n",
    "* The best model is the one which encompasses the maximum area under it.\n",
    "* In the adjacent diagram, amongst the two curves, the model that resulted in the red one should be chosen as it clearly covers more area than the blue one\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d_3qanOZqCaG"
   },
   "source": [
    "#### When to use recall and when to you precision\n",
    "\n",
    "* We have thousands of free customers registering in our website every week. The call center team wants to call them all, but it is imposible, so they ask me to select those with good chances to be a buyer (with high temperature is how we refer to them). We don't care to call a guy that is not going to buy (so precision is not important) but for us is very important that all of them with high temperature are always in my selection, so they don't go without buying. That means that my model needs to have a high recall, no matter if the precision goes to hell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cq_trb63qCaG"
   },
   "source": [
    " ## Python Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mxz4KP5wqCaG"
   },
   "outputs": [],
   "source": [
    "#Let's start with importing necessary libraries\n",
    "\n",
    "import pandas as pd# reading the file other necessary operation  \n",
    "import numpy as np# from that we can get mean median and other operation\n",
    "from sklearn.preprocessing import StandardScaler # for scaling the data \n",
    "from sklearn.linear_model  import LogisticRegression # importing logoistic regression\n",
    "from sklearn.model_selection import train_test_split # for splitting the data in to trainning and testing \n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, roc_auc_score #metric to check model performance\n",
    "import matplotlib.pyplot as plt # visualization library , analysis of data \n",
    "import seaborn as sns # visualization library , analysis of data\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # to ignore warnings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oI06dSuoqCaH"
   },
   "source": [
    "# Businesscase:-to predict whether a patient will have diabetes or not??\n",
    "# Binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 357,
     "status": "ok",
     "timestamp": 1625052259183,
     "user": {
      "displayName": "Shubhangi Sakarkar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjiJriRrUWKSeoxmYnVoL2uz2i6E3RLOwZgeqHG=s64",
      "userId": "12180749557274197061"
     },
     "user_tz": 420
    },
    "id": "mqBRbWCsqCaH",
    "outputId": "934690be-8a0c-4151-a99f-6794098b67be",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"diabetes1.csv\") # Reading the Data\n",
    "data.head()# it will give you first 5 rowsa\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "58ZhGjDdqCaJ"
   },
   "source": [
    "## Basic Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Outcome.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZA57dovqRbMF",
    "outputId": "4e291641-9710-4727-fa61-cd009f677bce"
   },
   "outputs": [],
   "source": [
    "data.head()#it will give you first  5 rows \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bajUtDcQqCaJ",
    "outputId": "58ad4904-7ac3-49e4-f8b1-5e9565333854"
   },
   "outputs": [],
   "source": [
    "data.tail()#it will give you last 5 rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2RnM13f6qCaI",
    "outputId": "b4a2c3ff-3033-4cc1-ad41-c1d79f881f41"
   },
   "outputs": [],
   "source": [
    "data.info()# To check  data type and  null value of all columns  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NZfst1RYqCaJ",
    "outputId": "efef102b-ff7c-4a58-cdc3-ad250b604376",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.describe()#used to view some basic statistical details like percentile, mean, std etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V7qerIZ7RbMi",
    "outputId": "ad367322-d52d-4991-bbf9-8a9a0d3e6695"
   },
   "outputs": [],
   "source": [
    "data['Pregnancies'].dtype # Checking the data type of particular column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NsmWOqUBqCaI",
    "outputId": "e2ac5bd2-8f15-4395-da14-872e3631451b"
   },
   "outputs": [],
   "source": [
    "data['BloodPressure'].dtype== 'int32' # checking whether a particular column has int32 datatype or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cPKe0biRqCaJ"
   },
   "outputs": [],
   "source": [
    "## Task:-Do the all feature analysis with the help of google.(Healthline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GPpEWbgHqCaK"
   },
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kUq_SrXLqCaK"
   },
   "source": [
    "### Univariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install sweetviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "executionInfo": {
     "elapsed": 120,
     "status": "error",
     "timestamp": 1637126457776,
     "user": {
      "displayName": "piyush shukla",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgUuYV50Asq1o00Uu3NqdMzxzYEOhWRSyZGJVOi9Q=s64",
      "userId": "08353895447701455330"
     },
     "user_tz": -330
    },
    "id": "t7dr5c5vqCaK",
    "outputId": "f1ac2508-bc93-48fc-d60c-2a23b084d045"
   },
   "outputs": [],
   "source": [
    "# In-depth EDA (target analysis, comparison, feature analysis, correlation) \n",
    "import sweetviz as sv #  library for univariant analysis\n",
    "my_report = sv.analyze(data)## pass the original dataframe\n",
    "my_report.show_html() # Default arguments will generate to \"SWEETVIZ_REPORT.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pslRpYqzqCaM"
   },
   "outputs": [],
   "source": [
    "# let's see how data is distributed for every column\n",
    "\n",
    "# figsize defines canvas size, gives figure dimension (width, height) in inches\n",
    "plt.figure(figsize=(20,25), facecolor='white')  # plt.figure()\n",
    "\n",
    "\n",
    "plotnumber = 1    # maintian count for graph\n",
    "\n",
    "for column in data:\n",
    "    if plotnumber<=9 :                      # as there are 9 columns in the data\n",
    "        ax = plt.subplot(3,3,plotnumber)    # plotting 9 graphs (3-rows,3-columns) ,plotnumber is for count \n",
    "        sns.distplot(data[column])          #plotting dist plot to know distribution\n",
    "        plt.xlabel(column,fontsize=20)\n",
    "        \n",
    "    plotnumber += 1   # plotnumber = plotnumber + 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cX-8ym0sqCaL"
   },
   "source": [
    "### Bivariate Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T_UPMzMbqCaL"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,25), facecolor='white')# defining  canvas size\n",
    "plotnumber = 1 # initializing plotnumber variable to 1 it will maintain the count of how many graph is going to plot in canvas \n",
    "\n",
    "for column in data.columns:               # iteration of columns / acessing the columns from  dataset \n",
    "    if plotnumber<=9 :                    # as there are 9 columns in the data\n",
    "        ax = plt.subplot(3,3,plotnumber)  # plotting 9 graphs (3-rows,3-columns) ,plotnumber is for count  \n",
    "        sns.histplot(x=data[column],hue=data.Outcome) ## it give frequency hue =value counts\n",
    "        plt.xlabel(column,fontsize=20)    #assigning name to x-axis and \"name\" font size is 20\n",
    "        plt.ylabel('Outcome',fontsize=20) #assigning name to y-axis and \"name\" font size is 20\n",
    "    plotnumber+=1                         # increment of plotnumber \n",
    "plt.show()                                # to show graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k-bpSrBPRbNQ"
   },
   "source": [
    "# Data preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 180
    },
    "executionInfo": {
     "elapsed": 526,
     "status": "error",
     "timestamp": 1637126803401,
     "user": {
      "displayName": "piyush shukla",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgUuYV50Asq1o00Uu3NqdMzxzYEOhWRSyZGJVOi9Q=s64",
      "userId": "08353895447701455330"
     },
     "user_tz": -330
    },
    "id": "War36D8IqCaM",
    "outputId": "71ae1eed-0f21-4aef-c2ca-8059cef2360c"
   },
   "outputs": [],
   "source": [
    "## get the missing values\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fMWpWHoQqCaM"
   },
   "source": [
    "### It seems that there are no missing values in our data. Great, let's see the distribution of data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6iFRqxVOqCaM"
   },
   "source": [
    "We can see there is some skewness in the data, let's deal with data.\n",
    "\n",
    "Also, we can see there few data for columns Glucose, Insulin, skin thickness, BMI and Blood Pressure which have value as 0. That's not possible. You can do a quick search to see that one cannot have 0 values for these.\n",
    "Let's deal with that. we can either remove such data or simply replace it with their respective mean values.\n",
    "Let's do the latter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-YJaHUFDqCaN",
    "outputId": "453f46c9-459e-494e-d3e3-cc77c47ed819"
   },
   "outputs": [],
   "source": [
    "data.loc[data['BMI']==0]  # how many 0 entry in the bmi column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AcLfXilvqCaN",
    "outputId": "132dc9a0-14b2-46e0-ba4e-dcfdacb071db"
   },
   "outputs": [],
   "source": [
    "data['BMI'].mean()  #bmi column mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U6A5ysNIqCaN"
   },
   "outputs": [],
   "source": [
    "# replacing zero values with the mean of the column\n",
    "data['BMI'] = data['BMI'].replace(0,data['BMI'].mean())#replacing 0 with mean of the bmi \n",
    "data['BloodPressure'] = data['BloodPressure'].replace(0,data['BloodPressure'].mean())#replacing 0 with mean of the Bloodpressure \n",
    "data['Glucose'] = data['Glucose'].replace(0,data['Glucose'].mean())##replacing 0 with mean of the Glucose\n",
    "data['Insulin'] = data['Insulin'].replace(0,data['Insulin'].mean())#replacing 0 with mean of the Insulin\n",
    "data['SkinThickness'] = data['SkinThickness'].replace(0,data['SkinThickness'].mean())#replacing 0 with mean of the Skinthickness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9ZSY80M5qCaN",
    "outputId": "4b8735bc-b68f-4593-ae48-2e8b6bb96dde"
   },
   "outputs": [],
   "source": [
    "# let's see how data is distributed for every column\n",
    "plt.figure(figsize=(20,25), facecolor='white')\n",
    "plotnumber = 1\n",
    "\n",
    "for column in data:\n",
    "    if plotnumber<=9 :\n",
    "        ax = plt.subplot(3,3,plotnumber)\n",
    "        sns.histplot(data[column])\n",
    "        plt.xlabel(column,fontsize=20)\n",
    "        \n",
    "    plotnumber+=1\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RlJ7qnbwqCaO"
   },
   "source": [
    "The data looks much better now than before. We will start our analysis with this data now as we don't want to lose important information.\n",
    "If our model doesn't work with accuracy, we will come back for more preprocessing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HKXcRdUuqCaO"
   },
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mDzIsWc3qCaP",
    "outputId": "ea427c76-e3a0-4599-b14f-b4bc3d54b1f3"
   },
   "outputs": [],
   "source": [
    "sns.heatmap(data.drop('Outcome',axis=1).corr())# checking for correlation\n",
    "## No correlated features are present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "23ULBkahqCaP",
    "outputId": "af292519-5509-43a2-c580-b0eea5b8a628"
   },
   "outputs": [],
   "source": [
    "## checking the duplicate rows\n",
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Outcome.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "__lS17L4qCaP",
    "outputId": "48243df3-db8a-4ff3-eec1-9fa75fceeaf5"
   },
   "outputs": [],
   "source": [
    "## checking the constant features\n",
    "data.describe()\n",
    "## the standard deviation is not zero for any feature,so there are no constant features in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dRNKNqD5qCaP"
   },
   "source": [
    "## Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lb_tSHf3qCaP"
   },
   "outputs": [],
   "source": [
    "## Defining X and y and creating dependent and independent variables\n",
    "X = data.drop(columns = ['Outcome']) ## independent variable\n",
    "y = data['Outcome'] ## Dependent or target variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xd84w7cKqCaP",
    "outputId": "2cdd3e16-5a7a-4870-efc4-7694c258ba6d"
   },
   "outputs": [],
   "source": [
    "X "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "itUjNeGdqCaQ"
   },
   "outputs": [],
   "source": [
    "## scaling the data as all features seems to be near to normal distribution\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "scalar = StandardScaler()           ## object creation\n",
    "X_scaled = scalar.fit_transform(X)  # scaling independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MuwMW6eRqCaQ",
    "outputId": "85982443-e2c9-4dca-9b9a-c2f60dec4286"
   },
   "outputs": [],
   "source": [
    "X_scaled #scaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n7z0KJ5GqCaQ"
   },
   "outputs": [],
   "source": [
    "## splitting training and testing data\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(X_scaled,y, test_size= 0.25,random_state = 355)#splitting data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 333,
     "status": "ok",
     "timestamp": 1625052308030,
     "user": {
      "displayName": "Shubhangi Sakarkar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjiJriRrUWKSeoxmYnVoL2uz2i6E3RLOwZgeqHG=s64",
      "userId": "12180749557274197061"
     },
     "user_tz": 420
    },
    "id": "jT2gyUKWqCaQ",
    "outputId": "b2c037a7-fd48-4d66-b4cd-6d4f404eb76d"
   },
   "outputs": [],
   "source": [
    "##Model creation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression()      #object creation of logistic regression\n",
    "    \n",
    "log_reg.fit(x_train,y_train)        #training model with training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xWIC6n6ARbN-"
   },
   "outputs": [],
   "source": [
    "y_train_pre=log_reg.predict(x_train)     # predicting y_train  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JASjgXjXqCaR"
   },
   "source": [
    "\n",
    "Let's see how well our model performs on the test data set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2CZOThWjqCaR"
   },
   "outputs": [],
   "source": [
    "y_pred = log_reg.predict(x_test) # predicting y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9V3ME3smRbOC",
    "outputId": "59d394dd-40cf-40ce-c94a-d7cc09fbe0ed"
   },
   "outputs": [],
   "source": [
    "y_train.shape # to know the shape of y_train (rows and columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8JEX3O3xRbOF",
    "outputId": "63714e40-6808-402f-e89a-57eca4ffd2bf"
   },
   "outputs": [],
   "source": [
    "y_pred.shape # to know the shape of y_pred (rows and columns )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L72a4ZNpRbOI"
   },
   "outputs": [],
   "source": [
    "# Evaluating the model\n",
    "\n",
    "from sklearn.metrics import accuracy_score,auc, confusion_matrix,precision_score,recall_score,f1_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7q1896ZZqCaR",
    "outputId": "3bfcb047-ee75-4435-cd13-722b68fb58fe"
   },
   "outputs": [],
   "source": [
    "## calculating accuracy for training set\n",
    "accuracy = accuracy_score(y_train,y_train_pre)# model traning accuracy  ... true positive, true negative\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bxhDq8Y-RbOL",
    "outputId": "cf1f0ec6-efe2-436b-eed5-501b5e789c8c"
   },
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test,y_pred)# model traning accuracy  \n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "puqu3JGTRbOO"
   },
   "source": [
    "Precision: What proportion of positive identifications was actually correct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fdkfYr9hqCaR",
    "outputId": "6bd1d940-972f-4ca8-d1a6-4faa27d502e8"
   },
   "outputs": [],
   "source": [
    "# Precison\n",
    "Precision = precision_score(y_test,y_pred)# the number of true positive divided by the total number of positive prediction\n",
    "Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L_Fe07aJRbOS"
   },
   "source": [
    "Our model has a precision of 0.7—in other words, out of total predicted positives, 70% are actually positives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2R0AHQz1RbOU"
   },
   "source": [
    "Recall: What proportion of actual positives was identified correctly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EKa1QPFAqCaS",
    "outputId": "d8533cd3-4809-4f72-c892-fea2e2fc34ab"
   },
   "outputs": [],
   "source": [
    "# Recall (recall varies from 0.0 to 1.0)\n",
    "Recall = recall_score(y_test,y_pred)# the total number of positive results how many positives were correctly predicted by the model.\n",
    "Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X1yeiNO5RbOY"
   },
   "source": [
    "Our model has a recall of 0.52—in other words, out of total actual positive values, model has predicted positives is only 52% \n",
    "\n",
    "Note: A model that produces no false negatives has a recall of 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "meLAlKiWqCaS",
    "outputId": "4ae5bd46-61cd-43f9-93e3-f7c2dad6bd87"
   },
   "outputs": [],
   "source": [
    "# F1 Score\n",
    "F1_Score = f1_score(y_test,y_pred)# when precision and recall both are important\n",
    "F1_Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w28oMPilqCaS",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##confusion matrix\n",
    "pd.crosstab(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g1uLUaGbqCaS"
   },
   "outputs": [],
   "source": [
    "report=classification_report(y_test, y_pred)# it will give precision,recall,f1 scores and accuracy  \n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F7Tdzk7YqCaS"
   },
   "outputs": [],
   "source": [
    "# Area Under Curve\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6uQbxsSJqCaT"
   },
   "source": [
    "**ROC PLOT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q8UOz9zfqCaT"
   },
   "outputs": [],
   "source": [
    "## Prediciting the probabilities of class 1\n",
    "probs=log_reg.predict_proba(x_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ixA4hsbMqCaT"
   },
   "outputs": [],
   "source": [
    "probs#probabilities of class 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-x-nrIJ0qCaT"
   },
   "outputs": [],
   "source": [
    "## Defining the threshold limit\n",
    "def predict_threshold (model,X_test,thresholds):\n",
    "    return np.where(model.predict_proba(X_test)[:,1]>thresholds, 1, 0)\n",
    "\n",
    "#checking where probability of class 1 is greater than threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_threshold(log_reg,x_test,thr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XJ6yHNjtqCaT",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "for thr in np.arange(0,1.0,0.1):# it will create matrix /array from range 0 to 1 with step 0.1\n",
    "    y_predict = predict_threshold(log_reg,x_test,thr)# it will check result  for  each threshold from 0 to 1\n",
    "    print(\"Threshold :\",thr)#printing threshold\n",
    "    print(confusion_matrix(y_test,y_predict))# confusion matrix for each prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yKdPbZuoqCaT"
   },
   "outputs": [],
   "source": [
    "## visualizing the roc plot\n",
    "def plot_roc_curve(fpr, tpr):# function to plot roc curve\n",
    "    plt.plot(fpr, tpr, color='orange', label='ROC')#line plot between fpr and tpr\n",
    "    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')# assigning name to  x axis\n",
    "    plt.ylabel('True Positive Rate')# assigning name to y axis\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')#assigning name to curve  \n",
    "    plt.legend()#area describing the elements of the graph\n",
    "    plt.show()#to show graph without location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LWW_fpdjqCaU"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score,roc_curve ## used to compare multiple models\n",
    "\n",
    "auc = roc_auc_score(y_test, probs) #roc curve \n",
    "print('AUC: %.2f' % auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3JLSePSQqCaU"
   },
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, probs)\n",
    "# it will return \n",
    "#Increasing false positive rates such that element i is the false positive rate of predictions with score >= thresholds[i].\n",
    "#Increasing true positive rates such that element i is the true positive rate of predictions with score >= thresholds[i].\n",
    "#Decreasing thresholds on the decision function used to compute fpr and tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u46WfpzkqCaU"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plot_roc_curve(fpr, tpr)#plotting ruc curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kdisMAIlqCaU"
   },
   "source": [
    "#### What is the significance of Roc curve and AUC?\n",
    "\n",
    "In real life, we create various models using different algorithms that we can use for classification purpose. We use AUC to determine which model is the best one to use for a given dataset. \n",
    "Suppose we have created Logistic regression, SVM as well as a clustering model for classification purpose. We will calculate AUC for all the models seperately. The model with highest AUC value will be the best model to use.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cld2Dp51qCaU"
   },
   "source": [
    "#### Advantages of Logisitic Regression\n",
    "\n",
    "* It is very simple and easy to implement.\n",
    "* The output is more informative than other classification algorithms\n",
    "* It expresses the relationship between independent and dependent variables\n",
    "* Very effective with linearly seperable data\n",
    "\n",
    "#### Disadvantages of Logisitic Regression\n",
    "\n",
    "* Not effective with data which are not linearly seperable \n",
    "* Not as powerful as other classification models\n",
    "* Multiclass classifications are much easier to do with other algorithms than logisitic regression\n",
    "* It can only predict categorical outcomes\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3dazRdvSqCaU"
   },
   "source": [
    "## Multiclass classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wXukBYR4qCaV"
   },
   "outputs": [],
   "source": [
    "\n",
    "data=pd.read_csv('iris.csv')# loading another dataset for multiclass classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l9JJ9OwEqCaV",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.head()# first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yLY2RWf6qCaV",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X=data.loc[:,['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']]#independent variable \n",
    "y=data.Species#dependent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NAwTfRKNqCaV"
   },
   "outputs": [],
   "source": [
    "y#dependent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MqwX4ZSxqCaV"
   },
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=42)# training and testing  data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7GnB4xY0qCaV"
   },
   "outputs": [],
   "source": [
    "LR=LogisticRegression(multi_class='ovr')# logistic regression for multiclass classification ovr-> one vs rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AslOA0eAqCaW"
   },
   "outputs": [],
   "source": [
    "LR.fit(X_train,y_train)#  training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_U3vUpYYqCaW"
   },
   "outputs": [],
   "source": [
    "y_hat=LR.predict(X_test)# predicting the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hZcsiZzcqCaW",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.crosstab(y_test,y_hat) # confusion matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "251ly1T_qCaW"
   },
   "outputs": [],
   "source": [
    "# Evaluating the model\n",
    "\n",
    "from sklearn.metrics import accuracy_score,auc, confusion_matrix,precision_score,recall_score,f1_score,classification_report\n",
    "#checking recall \n",
    "recall=recall_score(y_test,y_hat,average='weighted') # weighted: makes sure that \n",
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JdyF50z8qCaW"
   },
   "outputs": [],
   "source": [
    "precision=precision_score(y_test,y_hat,average='weighted')# checking precision\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TPXiEmA-qCaW"
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_hat))#recall,precision,f1 scores and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Logistic Regression.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
